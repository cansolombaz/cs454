{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS 454 TERM PROJECT - CAN SÖLÖMBAZ, MERT DEDEKÖY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"C:/Users/mrt/Desktop/ders/cs454/fashion-mnist_train.csv\")\n",
    "test=pd.read_csv(\"C:/Users/mrt/Desktop/ders/cs454/fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train.iloc[:,1:].values\n",
    "r_train=train.iloc[:,0].values\n",
    "x_test=test.iloc[:,1:].values\n",
    "r_test=test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, r_train, r_validation = train_test_split(x_train, r_train, test_size=1/6, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron\n",
    "\n",
    "Since the problem is not linearly seperable, mlp should be used to perform a nonlinear regression\n",
    "\n",
    "Network was designed as one output and one input and number of hidden units\n",
    "\n",
    "I used batch gradient descent to find parameters\n",
    "\n",
    "$ y^t = \\sum_{h=1}^H v_hz_h^t+v_0$ \n",
    "\n",
    "$ z_h = sigmoid(w_h^tx) $\n",
    "\n",
    "$ E(w,v|X) = 0.5\\sum_{t=1}^N (r^t-y^t)^2 $\n",
    "\n",
    "$\\Delta v_h = \\alpha \\sum_{t=1}^N (r^t-y^t)z_h^t$\n",
    "\n",
    "$ \\Delta w_hj = \\alpha \\sum_{t=1}^N (r^t-y^t)v_h z_h^t (1-z_h^t) x_j^t $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func():\n",
    "    loss=0\n",
    "    for data in range(50000):\n",
    "        for Class in range(10):\n",
    "            if r_train[data]==Class:\n",
    "                loss=+ np.log(y[Class,data])\n",
    "    loss=loss*-1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_params(alpha, number_of_H, x_train, r_train):\n",
    "\n",
    "    w_all=[]\n",
    "    v_all=[]\n",
    "    for H in range (2,number_of_H+1):\n",
    "        \n",
    "        # initialize parameters\n",
    "        x=np.ones((785,len(x_train)))\n",
    "        x[1:,:]=np.transpose(x_train)\n",
    "        v=np.random.uniform(-0.01,0.01,size=(10,H))#v_ih\n",
    "        w=np.random.uniform(-0.01,0.01,size=(H-1,len(x))) #w_hj      \n",
    "        z=1/(1+np.exp(-(w.dot(x))))\n",
    "        o=np.zeros((10,50000))\n",
    "        for i in range(50000):\n",
    "            o[:,i]=v[:,1:].dot(z)[:,i]+v[:,0]\n",
    "        y=np.exp(o)/(np.sum(np.exp(o),axis=0))\n",
    "        y=np.argmax(y,axis=0)\n",
    "\n",
    "    \n",
    "        epoch=0\n",
    "        \n",
    "        while True:\n",
    "        \n",
    "            delta_v=np.empty(H)\n",
    "            \n",
    "            sum_v0=0\n",
    "            for i in range(len(x_train)):\n",
    "                    sum_v0+=(r_train[i]-y[i])\n",
    "            delta_v[0]=alpha*sum_v0        \n",
    "            for h in range(H-1):\n",
    "                sum_1=0\n",
    "                for i in range(len(x_train)):\n",
    "                    sum_1+=(r_train[i]-y[i])*z[h,i]\n",
    "                delta_v[h+1]=alpha*sum_1\n",
    "            \n",
    "            \n",
    "            \n",
    "            delta_w=np.empty((H-1,len(x)))\n",
    "            \n",
    "            for h in range(H-1):  \n",
    "                for j in range(len(x)):\n",
    "                    sum_2=0\n",
    "                    for i in range(len(x_train)):\n",
    "                        sum_2+=(r_train[i]-y[i])*v[1:][h]*z[h,i]*(1-z[h,i])*x[j,i]\n",
    "                    delta_w[h,j]=alpha*sum_2\n",
    "            \n",
    "            \n",
    "            temp_v=v\n",
    "            v=np.add(v,delta_v,dtype=np.float64)\n",
    "            \n",
    "            \n",
    "            temp_w=w      \n",
    "            w=np.add(w,delta_w,dtype=np.float64)\n",
    "            \n",
    "    \n",
    "            \n",
    "            z=1/(1+np.exp(-(w.dot(x))))\n",
    "            o=np.zeros((10,50000))\n",
    "            for i in range(50000):\n",
    "                o[:,i]=v[:,1:].dot(z)[:,i]+v[:,0]\n",
    "            y=np.exp(o)/(np.sum(np.exp(o),axis=0))\n",
    "            y=np.argmax(y,axis=0)\n",
    "\n",
    "            \n",
    "   \n",
    "            epoch=epoch+1\n",
    "            \n",
    "            \n",
    "            \n",
    "            if (all(x <0.0001 for x in itertools.chain(*delta_w))) and (all(x <0.0001 for x in itertools.chain(*delta_v))):\n",
    "                w_all.append(w)\n",
    "                v_all.append(v)\n",
    "                break\n",
    "    \n",
    "    return w_all,v_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_all, v_all = mlp_params(0.01,10,x_train,r_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_results(w_all, v_all, x_data, r_data, number_of_H):\n",
    "    \n",
    "    all_mse=[]\n",
    "    y_all=[]\n",
    "    for H in range (number_of_H-1):\n",
    "        \n",
    "        x=np.ones((2,len(x_data)))\n",
    "        x[1,:]=x_data\n",
    "        z=1/(1+np.exp(-(w_all[H].dot(x))))\n",
    "        y=v_all[H][1:].dot(z)+v_all[H][0]\n",
    "        \n",
    "        y_all.append(y)\n",
    "        all_mse.append(mean_square_error(y,r_data))\n",
    "        \n",
    "    return all_mse,y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors_mlp,y_train = mlp_results(w_all, v_all, x_train, r_train, 10)\n",
    "validation_errors_mlp,y_validation = mlp_results(w_all, v_all, x_validation, r_validation, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_error(validation_errors,train_errors,H):\n",
    "    num_k=[k for k in range(2,H+1)] \n",
    "    plt.plot(num_k,validation_errors, label=\"validation error\")\n",
    "    plt.plot(num_k,train_errors, label=\"train error\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"mean square error\")\n",
    "    plt.xticks(num_k)\n",
    "    plt.show()\n",
    "plt_error(validation_errors_mlp,train_errors_mlp,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
